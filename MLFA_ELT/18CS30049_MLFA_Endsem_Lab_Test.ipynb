{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svvqtsqJykCy"
      },
      "source": [
        "# **MLFA Endsem Lab Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEXW_Ndd8Qb4"
      },
      "source": [
        "Consider a classification task involving a modified MNIST data having 1000 data items distributed across 10 classes. \n",
        "Each data is an image with 20x20 dimension, flattened to 400-dimension vector. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yIXNUUQ6yjEt"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLueaKgNwYv-"
      },
      "source": [
        "## **Question 1**\n",
        "\n",
        "- Implement Principal Component Analysis (PCA) to perform reduction of dimensionality to 100. \n",
        "\n",
        "- Design a Multi\u0002Layer Perceptron (MLP) classifier that takes as input the reduced vector and predicts its class.\n",
        "\n",
        "- Report classification accuracy by performing 5-fold cross validation. - Repeat the experiment with dimensionality reduced to 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO_HZLYrv8ig"
      },
      "outputs": [],
      "source": [
        "#Unzip MNIST data\n",
        "#I am using binary format, kindly upload the below zip file in the same directory as this ipynb file\n",
        "!unzip data-lab-test-13-binary.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIgLG3yBwleY",
        "outputId": "f9500b73-d882-4c13-e41d-e157dcc521ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 400) (1000,)\n"
          ]
        }
      ],
      "source": [
        "# Load the modified MNIST dataset\n",
        "X = np.load('data.npy')\n",
        "y = np.load('labels.npy')\n",
        "\n",
        "#Inspecting data dimensions\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WmpoYLAtwmYv"
      },
      "outputs": [],
      "source": [
        "def my_pca_fit(X, n_components):\n",
        "  # First we center the data\n",
        "  X_centered = X - np.mean(X, axis=0)\n",
        "\n",
        "  # Now, compute the covariance matrix\n",
        "  cov_matrix = np.cov(X_centered.T)\n",
        "\n",
        "  # Next, we compute the eigenvectors & eigenvalues of the covariance matrix\n",
        "  eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "\n",
        "  # Sorting the eigenvectors in descending order of eigenvalues\n",
        "  eigenvectors = eigenvectors[:, np.argsort(eigenvalues)[::-1]]\n",
        "\n",
        "  # Select the first n_components\n",
        "  eigenvectors = eigenvectors[:, : n_components]\n",
        "\n",
        "  return eigenvectors\n",
        "\n",
        "def my_pca_transform(X, eigenvectors): \n",
        "  # Again, first center the data\n",
        "  X_centered = X - np.mean(X, axis=0)\n",
        "  # Compute the reduced data (X_pca)\n",
        "  X_pca = np.dot(X_centered, eigenvectors)\n",
        "  return X_pca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhWJHqBMyy_E"
      },
      "source": [
        "Writing model in functional form so that we can use it for experiments with different parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UR6wgoZWwmd8"
      },
      "outputs": [],
      "source": [
        "def mlp_pca_model(X_reduced, y, n_folds, n_components):\n",
        "  # Define the MLP classifier\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000)\n",
        "\n",
        "  # Instantiating KFold object\n",
        "  kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "  # Perform cross validation\n",
        "  accuracies = list()\n",
        "  for train_idx, test_idx in kf.split(X):\n",
        "      #Consider current fold of data\n",
        "      X_train, y_train = X[train_idx], y[train_idx]\n",
        "      X_test, y_test = X[test_idx], y[test_idx]\n",
        "      \n",
        "      #Fit PCA on X_train\n",
        "      eigenvectors = my_pca_fit(X_train, n_components) \n",
        "\n",
        "      #Perform PCA on X_test to transform it to lower dimensionality\n",
        "      X_train_pca = my_pca_transform(X_train, eigenvectors)\n",
        "      \n",
        "      #Perform PCA on X_test to transform it to lower dimensionality\n",
        "      X_test_pca = my_pca_transform(X_test, eigenvectors)\n",
        "      \n",
        "      clf.fit(X_train_pca, y_train)\n",
        "      curr_acc = clf.score(X_test_pca, y_test)\n",
        "      accuracies.append(curr_acc)\n",
        "\n",
        "  mean_acc = np.round(np.mean(accuracies),3)\n",
        "  best_acc = np.round(np.max(accuracies),3)\n",
        "  return mean_acc, best_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YOHephdz6vR"
      },
      "source": [
        "PCA - Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nmcpwn7wmWM",
        "outputId": "aaab2fbb-b0f4-4bd7-e7b2-0d77b5b6a7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average accuracy of MLP model on data with 100 components: 0.722\n",
            "Maximum accuracy of MLP model on data with 100 components: 0.765\n"
          ]
        }
      ],
      "source": [
        "n_folds = 5  # no. of folds for cross validation\n",
        "n_components = 100  # no. of dimensions to which X will be reduced\n",
        "\n",
        "# Train the model and evaluate it\n",
        "mean_acc, best_acc = mlp_pca_model(X, y, n_folds, n_components)\n",
        "\n",
        "# Print the average & best k-fold classification accuracy\n",
        "print('Average accuracy of MLP model on data with', n_components, 'components:',mean_acc)\n",
        "print('Maximum accuracy of MLP model on data with', n_components, 'components:',best_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wjG6bKpz8Q5"
      },
      "source": [
        "PCA - Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXA88GABwVr6",
        "outputId": "82da03b8-a27f-4de1-fadd-e8d6e2b93213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average accuracy of MLP model on data with 200 components: 0.675\n",
            "Maximum accuracy of MLP model on data with 200 components: 0.715\n"
          ]
        }
      ],
      "source": [
        "n_folds = 5  # no. of folds for cross validation\n",
        "n_components = 200  # no. of dimensions to which X will be reduced\n",
        "\n",
        "# Train the model and evaluate it\n",
        "mean_acc, best_acc = mlp_pca_model(X, y, n_folds, n_components)\n",
        "\n",
        "# Print the average & best k-fold classification accuracy\n",
        "print('Average accuracy of MLP model on data with', n_components, 'components:',mean_acc)\n",
        "print('Maximum accuracy of MLP model on data with', n_components, 'components:',best_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXTaKeuz25pS"
      },
      "source": [
        "PCA - Experiment 3 (Additional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fImQhgv-z92Z",
        "outputId": "dab7baef-6346-42c5-92a3-e265e334c1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average accuracy of MLP model on data with 50 components: 0.729\n",
            "Maximum accuracy of MLP model on data with 50 components: 0.78\n"
          ]
        }
      ],
      "source": [
        "n_folds = 5  # no. of folds for cross validation\n",
        "n_components = 50  # no. of dimensions to which X will be reduced\n",
        "\n",
        "# Train the model and evaluate it\n",
        "mean_acc, best_acc = mlp_pca_model(X, y, n_folds, n_components)\n",
        "\n",
        "# Print the average & best k-fold classification accuracy\n",
        "print('Average accuracy of MLP model on data with', n_components, 'components:',mean_acc)\n",
        "print('Maximum accuracy of MLP model on data with', n_components, 'components:',best_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clBW5xsx27NA"
      },
      "source": [
        "Observation: Model accuracy increasing on reducing n_components for PCA Experiments\n",
        "\n",
        "\n",
        "---------------------------------------------------------------\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YVZ1YhO8MIe"
      },
      "source": [
        "## **Question 2**\n",
        "\n",
        "- Implement Linear Discriminant Analysis (LDA) to perform reduction of dimensionality to 100. \n",
        "\n",
        "- Design a Multi\u0002Layer Perceptron (MLP) classifier that takes as input the reduced vector and predicts its class.\n",
        "\n",
        "- Report classification accuracy by performing 5-fold cross validation. - Repeat the experiment with dimensionality reduced to 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uwY5ZiX6EaR_"
      },
      "outputs": [],
      "source": [
        "# Wrting my psuedo code for LDA part to explain the core logic\n",
        "\n",
        "# Step 1: Compute the mean vectors of each class\n",
        "# Step 2: Compute within-class Scatter matrix (Sw)\n",
        "# Step 3: Add regularization to Sw --> we are doing this to handle edge case of singular matrix\n",
        "# Step 4: Computing between-class Scatter matrix (Sb)\n",
        "# Step 5: Computing the eigenvalues & eigenvectors of Sw^-1 * Sb\n",
        "# Step 6: Sorting eignvectors oin decsending order on the basis of eignvalues\n",
        "# Step 7: Select the top n_components eigenvectors\n",
        "# Step 8: Return W (will be later used to transform both X_train and X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oqM81mQI7uSs"
      },
      "outputs": [],
      "source": [
        "def my_lda_fit(X, y, n_components):\n",
        "    # Compute the mean vectors of each class\n",
        "    mean_vecs = list()\n",
        "    for c in np.unique(y):\n",
        "        mean_vecs.append(np.mean(X[y==c], axis=0))\n",
        "    \n",
        "    # Computing within-class Scatter matrix (Sw)\n",
        "    dim1 = X.shape[1]\n",
        "    Sw = np.zeros((dim1, dim1))\n",
        "    for c, mean_vec in zip(np.unique(y), mean_vecs):\n",
        "        class_scatter = np.zeros((dim1, dim1))\n",
        "        for x in X[y==c]:\n",
        "            x = x.reshape(-1, 1)\n",
        "            mean_vec = mean_vec.reshape(-1, 1)\n",
        "            class_scatter += (x - mean_vec).dot((x - mean_vec).T)\n",
        "        Sw += class_scatter\n",
        "\n",
        "    # Adding regularization to Sw --> we are doing this to handle edge case of singular matrix\n",
        "    Sw += np.eye(dim1) * 1e-8\n",
        "    \n",
        "    # Now Computing between-class Scatter matrix (Sb)\n",
        "    Sb = np.zeros((dim1, dim1))\n",
        "    overall_mean = np.mean(X, axis=0)\n",
        "    for c, mean_vec in zip(np.unique(y), mean_vecs):\n",
        "        n = X[y==c].shape[0]\n",
        "        mean_vec = mean_vec.reshape(-1, 1)\n",
        "        overall_mean = overall_mean.reshape(-1, 1)\n",
        "        Sb += n * (mean_vec - overall_mean).dot((mean_vec - overall_mean).T)\n",
        "    \n",
        "    # Next, we compute the eigenvalues & eigenvectors of Sw^-1 * Sb\n",
        "    eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(Sw).dot(Sb))\n",
        "\n",
        "    # Get the real part of eigenvalues and eigenvectors to remove imaginary data\n",
        "    eig_vals = np.real(eig_vals)\n",
        "    eig_vecs = np.real(eig_vecs)\n",
        "\n",
        "    eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
        "    eig_pairs.sort(key=lambda x: x[0], reverse=True) #sorting vectors in decsending order on eignvales\n",
        "    \n",
        "    # Select the top n_components eigenvectors\n",
        "    W = np.hstack([eig_pairs[i][1].reshape(-1,1) for i in range(n_components)])\n",
        "      \n",
        "    return W\n",
        "\n",
        "   \n",
        "def my_lda_transform(X, W):\n",
        "    X_proj = np.dot(X, W)    # Projected data onto the LDA space\n",
        "    return X_proj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LQccyHNE7uSt"
      },
      "outputs": [],
      "source": [
        "def mlp_lda_model(X, y, n_folds, n_components):\n",
        "  # Define the MLP classifier\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000)\n",
        "\n",
        "  # Instantiating KFold object\n",
        "  kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "  # Perform cross validation\n",
        "  accuracies = list()\n",
        "  for train_idx, test_idx in kf.split(X):\n",
        "      #Consider current fold of data\n",
        "      X_train, y_train = X[train_idx], y[train_idx]\n",
        "      X_test, y_test = X[test_idx], y[test_idx]\n",
        "      \n",
        "      #Fit LDA on X_train\n",
        "      W = my_lda_fit(X_train, y_train, n_components) \n",
        "\n",
        "      #Perform LDA on X_test to transform it to lower dimensionality\n",
        "      X_train_lda = my_lda_transform(X_train, W)\n",
        "      \n",
        "      #Perform LDA on X_test to transform it to lower dimensionality\n",
        "      X_test_lda = my_lda_transform(X_test, W)\n",
        "      \n",
        "      clf.fit(X_train_lda, y_train)\n",
        "      curr_acc = clf.score(X_test_lda, y_test)\n",
        "      accuracies.append(curr_acc)\n",
        "\n",
        "  mean_acc = np.round(np.mean(accuracies),3)\n",
        "  best_acc = np.round(np.max(accuracies),3)\n",
        "  return mean_acc, best_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Ji1m2Q7uSt"
      },
      "source": [
        "LDA - Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy5KcnFS7uSt",
        "outputId": "0a24d624-0aa6-43f3-9fc0-cbc0cc8a5943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average accuracy of MLP model on data with 100 components: 0.623\n",
            "Maximum accuracy of MLP model on data with 100 components: 0.67\n"
          ]
        }
      ],
      "source": [
        "n_folds = 5  # no. of folds for cross validation\n",
        "n_components = 100  # no. of dimensions to which X will be reduced\n",
        "\n",
        "# Train the model and evaluate it\n",
        "mean_acc, best_acc = mlp_lda_model(X, y, n_folds, n_components)\n",
        "\n",
        "# Print the average & best k-fold classification accuracy\n",
        "print('Average accuracy of MLP model on data with', n_components, 'components:',mean_acc)\n",
        "print('Maximum accuracy of MLP model on data with', n_components, 'components:',best_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCiVkd0V7uSt"
      },
      "source": [
        "LDA - Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxqbsZy27uSt",
        "outputId": "aa4b779b-894b-47cd-b6dc-c0484e1b6eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average accuracy of MLP model on data with 200 components: 0.613\n",
            "Maximum accuracy of MLP model on data with 200 components: 0.68\n"
          ]
        }
      ],
      "source": [
        "n_folds = 5  # no. of folds for cross validation\n",
        "n_components = 200  # no. of dimensions to which X will be reduced\n",
        "\n",
        "# Train the model and evaluate it\n",
        "mean_acc, best_acc = mlp_lda_model(X, y, n_folds, n_components)\n",
        "\n",
        "# Print the average & best k-fold classification accuracy\n",
        "print('Average accuracy of MLP model on data with', n_components, 'components:',mean_acc)\n",
        "print('Maximum accuracy of MLP model on data with', n_components, 'components:',best_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4jZUu9_wD5Tl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
